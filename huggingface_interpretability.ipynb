{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NyXYrJnkw6ve"},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from itertools import permutations\n","from captum.attr import (\n","    FeatureAblation,\n","    LLMAttribution,\n","    TextTokenInput,\n","    TextTemplateInput,\n",")\n","from constants import *\n","import torch\n","import json\n","import os\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4iWDqrLdw6vf"},"outputs":[],"source":["def load_model(hf_tag, bnb_config):\n","    n_gpus = torch.cuda.device_count()\n","    if bnb_config is None:\n","        model = AutoModelForCausalLM.from_pretrained(hf_tag, device_map=\"auto\")\n","    else:\n","        model = AutoModelForCausalLM.from_pretrained(\n","            hf_tag, quantization_config=bnb_config, device_map=\"auto\"\n","        )\n","    tokenizer = AutoTokenizer.from_pretrained(hf_tag, token=True)\n","    return model, tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e8xFEeprw6vf"},"outputs":[],"source":["def create_bnb_config():\n","    return BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_use_double_quant=True,\n","        bnb_4bit_quant_type=\"nf4\",\n","        bnb_4bit_compute_dtype=torch.bfloat16,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LLv0P1zHTSh8"},"outputs":[],"source":["def get_prompt(system_prompt, user_prompt):\n","    prompt = []\n","    if system_prompt:\n","        prompt.append({\"role\": \"system\", \"content\": system_prompt})\n","    prompt.append({\"role\": \"user\", \"content\": user_prompt})\n","    return prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AdABzwz5w6vf"},"outputs":[],"source":["RESULTS_FOLDER = \"results\"\n","GENERATED_CODE_FOLDER = os.path.join(RESULTS_FOLDER, \"generated_code\")\n","ATTRIBUTE_CODE_FOLDER = os.path.join(RESULTS_FOLDER, \"feature_ablation\")\n","MODEL = \"granitecode3b\"\n","TASK = \"int_cmp\"\n","HF_MODEL_TAG = HUGGINGFACE_TAGS[MODEL]\n","QUANTIZE = True\n","LANG2LANG = list(permutations(LANGS.keys(), 2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OQHM5yxew6vf"},"outputs":[],"source":["if QUANTIZE:\n","    model, tokenizer = load_model(HF_MODEL_TAG, create_bnb_config())\n","else:\n","    model, tokenizer = load_model(HF_MODEL_TAG, None)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZaMxQc2o6az"},"outputs":[],"source":["fa = FeatureAblation(model)\n","llm_attr = LLMAttribution(fa, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ubz9Q1b9CnDm"},"outputs":[],"source":["# reference from https://stackoverflow.com/a/61305389\n","matcher = re.compile(r'((?:(\\\"+)[\\s\\S]+?\\2|[^\"\\n]+)+)')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QoAZjqQMo9XV"},"outputs":[],"source":["for FROM_LANG, TO_LANG in LANG2LANG:\n","    if FROM_LANG in [\"C\", \"CPP\", \"GO\"] or (FROM_LANG in [\"JAVA\"] and TO_LANG in [\"C\", \"CPP\", \"GO\", \"JS\"]):\n","        continue\n","    from_code = REFERENCE_CODE[FROM_LANG][TASK].strip()\n","    to_code_path = os.path.join(\n","        GENERATED_CODE_FOLDER,\n","        f\"{MODEL}-{TASK}-{FROM_LANG.lower()}-{TO_LANG.lower()}.{TO_LANG.lower()}\",\n","    )\n","    if not os.path.exists(to_code_path):\n","        continue\n","    to_code = open(to_code_path, \"r\").read().strip()\n","    if not to_code:\n","        continue\n","    values = [x[0] for x in matcher.findall(from_code)]\n","    code_lines = \"\\n\".join([\"{}\" for _ in range(len(values))])\n","    prompt = f\"Convert the following code from {LANGS[FROM_LANG]} to {LANGS[TO_LANG]}. \"\n","    prompt += f\"This is the requirement for the code - {TASK_DESCRIPTION[TASK]}\\n\"\n","    formatted_prompt = prompt + \"```\\n\" + code_lines + \"\\n```\\n\"\n","    if HUGGINGFACE_SYSTEM_PROMPT_SUPPORT[MODEL]:\n","        chat_prompt = get_prompt(\n","            \"You are a helpful code conversion assistant.\", formatted_prompt\n","        )\n","    else:\n","        chat_prompt = get_prompt(None, formatted_prompt)\n","    template = tokenizer.apply_chat_template(chat_prompt, tokenize=False)\n","    inp = TextTemplateInput(template=template, values=values)\n","    attr_res = llm_attr.attribute(inp, target=to_code)\n","    d = {\n","        \"input_tokens\": [str(x) for x in attr_res.input_tokens],\n","        \"output_tokens\": [str(x) for x in attr_res.output_tokens],\n","        \"token_attr\": attr_res.token_attr.squeeze().tolist(),\n","        \"seq_attr\": attr_res.seq_attr.tolist(),\n","    }\n","    json.dump(\n","        d,\n","        open(\n","            os.path.join(\n","                ATTRIBUTE_CODE_FOLDER,\n","                f\"{MODEL}-{TASK}-{FROM_LANG.lower()}-{TO_LANG.lower()}.json\",\n","            ),\n","            \"w\",\n","        ),\n","    )\n","    print(f\"Done for {MODEL} {TASK} {FROM_LANG.lower()} {TO_LANG.lower()}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":0}
