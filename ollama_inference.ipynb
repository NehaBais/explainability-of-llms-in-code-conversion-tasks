{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Code Conversion using Ollama Inference Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from itertools import permutations\n",
                "from constants import *\n",
                "\n",
                "import ollama\n",
                "import os"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "RESULTS_FOLDER = \"results\"\n",
                "GENERATED_CODE_FOLDER = os.path.join(RESULTS_FOLDER, \"generated_code\")\n",
                "REJECTED_CODE_FOLDER = os.path.join(RESULTS_FOLDER, \"rejected_code\")\n",
                "MODEL = \"deepseekcoderv2\"\n",
                "LANG2LANG = list(permutations(LANGS.keys(), 2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_prompt(system_prompt, user_prompt):\n",
                "    prompt = []\n",
                "    if system_prompt:\n",
                "        prompt.append({\"role\": \"system\", \"content\": system_prompt})\n",
                "    prompt.append({\"role\": \"user\", \"content\": user_prompt})\n",
                "    return prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt = \"Convert the following code from {} to {}. This is the requirement for the code - {}\\n```{}```\\n\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ollama.pull(OLLAMA_TAGS[MODEL])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for TASK in TASKS.keys():\n",
                "    for idx, (lang1, lang2) in enumerate(LANG2LANG):\n",
                "        if REFERENCE_CODE[lang1][TASK] == \"\":\n",
                "            continue\n",
                "        if os.path.exists(\n",
                "            os.path.join(\n",
                "                GENERATED_CODE_FOLDER,\n",
                "                f\"{MODEL}-{TASK}-{lang1.lower()}-{lang2.lower()}.md\",\n",
                "            )\n",
                "        ):\n",
                "            continue\n",
                "        if os.path.exists(\n",
                "            os.path.join(\n",
                "                REJECTED_CODE_FOLDER,\n",
                "                f\"{MODEL}-{TASK}-{lang1.lower()}-{lang2.lower()}.md\",\n",
                "            )\n",
                "        ):\n",
                "            continue\n",
                "        formatted_prompt = prompt.format(\n",
                "            LANGS[lang1],\n",
                "            LANGS[lang2],\n",
                "            TASK_DESCRIPTION[TASK],\n",
                "            REFERENCE_CODE[lang1][TASK],\n",
                "        )\n",
                "        if OLLAMA_SYSTEM_PROMPT_SUPPORT[MODEL]:\n",
                "            chat_prompt = get_prompt(\n",
                "                \"You are a helpful code conversion assistant.\", formatted_prompt\n",
                "            )\n",
                "        else:\n",
                "            chat_prompt = get_prompt(None, formatted_prompt)\n",
                "        try:\n",
                "            rsp = ollama.chat(\n",
                "                OLLAMA_TAGS[MODEL],\n",
                "                messages=chat_prompt,\n",
                "                options={\"seed\": 42, \"timeout\": 60},\n",
                "            )\n",
                "        except:\n",
                "            try:\n",
                "                rsp = ollama.chat(\n",
                "                    OLLAMA_TAGS[MODEL],\n",
                "                    messages=chat_prompt,\n",
                "                    options={\"seed\": 41, \"timeout\": 60},\n",
                "                )\n",
                "            except:\n",
                "                print(f\"timeout in {MODEL} {TASK} {lang1} {lang2}\")\n",
                "                with open(\n",
                "                    os.path.join(\n",
                "                        REJECTED_CODE_FOLDER,\n",
                "                        f\"{MODEL}-{TASK}-{lang1.lower()}-{lang2.lower()}.md\",\n",
                "                    ),\n",
                "                    \"w\",\n",
                "                ) as fp:\n",
                "                    fp.write(\"\\n\")\n",
                "                continue\n",
                "        with open(\n",
                "            os.path.join(\n",
                "                GENERATED_CODE_FOLDER,\n",
                "                f\"{MODEL}-{TASK}-{lang1.lower()}-{lang2.lower()}.md\",\n",
                "            ),\n",
                "            \"w\",\n",
                "        ) as fp:\n",
                "            fp.write(rsp[\"message\"][\"content\"] + \"\\n\")\n",
                "        print(f\"completed {MODEL} {TASK} {lang1} {lang2}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ollama.delete(OLLAMA_TAGS[MODEL])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}