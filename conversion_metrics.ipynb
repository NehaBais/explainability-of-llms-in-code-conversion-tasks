{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from constants import *\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = \"results\"\n",
    "REFERENCE_CODE_FOLDER = os.path.join(RESULTS_FOLDER, \"reference_code\")\n",
    "ACCEPTED_CODE_FOLDER = os.path.join(RESULTS_FOLDER, \"accepted_code\")\n",
    "REJECTED_CODE_FOLDER = os.path.join(RESULTS_FOLDER, \"rejected_code\")\n",
    "HF_TOKEN = open(\".token\", \"r\").read().strip()\n",
    "BLEU = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(os.path.join(RESULTS_FOLDER, \"compilation_log.txt\"), \"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"2024-09-06 16:55:50 - Compilation and syntax check failed: deepseekcoder7b-bit_ops-py-c.c: Command '['gcc', '/tmp/deepseekcoder7b-bit_ops-py-c.c', '-o', '/tmp/deepseekcoder7b-bit_ops-py-c.c.out']' returned non-zero exit status 1.\\n\",\n",
       " '2024-09-06 16:55:50 - Compilation successful: codellama7b-int_factors-rs-c.c\\n',\n",
       " \"2024-09-06 16:55:51 - Compilation and syntax check failed: magicoder7b-int_factors-c-cpp.cpp: Command '['g++', '/tmp/magicoder7b-int_factors-c-cpp.cpp', '-o', '/tmp/magicoder7b-int_factors-c-cpp.cpp.out']' returned non-zero exit status 1.\\n\",\n",
       " '2024-09-06 16:55:51 - Compilation successful: codellama7b-int_cmp-cpp-rs.rs\\n',\n",
       " '2024-09-06 16:55:51 - Syntax check successful: codegeex4-bit_ops-py-js.js\\n',\n",
       " '2024-09-06 16:55:51 - Syntax check successful: deepseekcoder7b-bit_ops-c-js.js\\n',\n",
       " \"2024-09-06 16:55:52 - Compilation and syntax check failed: granitecode3b-int_factors-java-cpp.cpp: Command '['g++', '/tmp/granitecode3b-int_factors-java-cpp.cpp', '-o', '/tmp/granitecode3b-int_factors-java-cpp.cpp.out']' returned non-zero exit status 1.\\n\",\n",
       " '2024-09-06 16:55:52 - Syntax check successful: codegeex4-bit_ops-js-py.py\\n',\n",
       " \"2024-09-06 16:55:52 - Compilation and syntax check failed: codegemma7b-int_factors-js-c.c: Command '['gcc', '/tmp/codegemma7b-int_factors-js-c.c', '-o', '/tmp/codegemma7b-int_factors-js-c.c.out']' returned non-zero exit status 1.\\n\",\n",
       " \"2024-09-06 16:55:52 - Compilation and syntax check failed: granitecode3b-int_cmp-py-cpp.cpp: Command '['g++', '/tmp/granitecode3b-int_cmp-py-cpp.cpp', '-o', '/tmp/granitecode3b-int_cmp-py-cpp.cpp.out']' returned non-zero exit status 1.\\n\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_row_exists(df, m, t, fl, tl):\n",
    "    return (\n",
    "        (df[\"model\"] == m)\n",
    "        & (df[\"task\"] == t)\n",
    "        & (df[\"from_lang\"] == fl)\n",
    "        & (df[\"to_lang\"] == tl)\n",
    "    ).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "tasks = []\n",
    "from_langs = []\n",
    "to_langs = []\n",
    "successes = []\n",
    "valids = []\n",
    "bleus = []\n",
    "\n",
    "if os.path.exists(os.path.join(RESULTS_FOLDER, f\"metrics.csv\")):\n",
    "    metrics = pd.read_csv(os.path.join(RESULTS_FOLDER, f\"metrics.csv\"))\n",
    "else:\n",
    "    metrics = pd.DataFrame(\n",
    "        {\n",
    "            \"model\": models,\n",
    "            \"task\": tasks,\n",
    "            \"from_lang\": from_langs,\n",
    "            \"to_lang\": to_langs,\n",
    "            \"success\": successes,\n",
    "            \"valid\": valids,\n",
    "            \"bleu\": bleus,\n",
    "        }\n",
    "    )\n",
    "\n",
    "cnt = 0\n",
    "for line in lines:\n",
    "    valid = 0\n",
    "    if \"successful\" in line:\n",
    "        valid = 1\n",
    "    line = line.strip()\n",
    "    line = [x.strip() for x in line.split(\":\")][3]\n",
    "    line = line.split(\".\")[0]\n",
    "    line = line.split(\"-\")\n",
    "    m = line[0]\n",
    "    t = line[1]\n",
    "    fl = line[2]\n",
    "    tl = line[3]\n",
    "    if check_row_exists(metrics, m, t, fl, tl):\n",
    "        continue\n",
    "    cnt += 1\n",
    "    models.append(m)\n",
    "    tasks.append(t)\n",
    "    from_langs.append(fl)\n",
    "    to_langs.append(tl)\n",
    "    valids.append(valid)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        HUGGINGFACE_TAGS[m], token=HF_TOKEN, trust_remote_code=True\n",
    "    )\n",
    "    ref_code = (\n",
    "        open(os.path.join(REFERENCE_CODE_FOLDER, f\"{t}.{tl}\"), \"r\").read().strip()\n",
    "    )\n",
    "    gen_code = (\n",
    "        open(os.path.join(ACCEPTED_CODE_FOLDER, f\"{m}-{t}-{fl}-{tl}.{tl}\"), \"r\")\n",
    "        .read()\n",
    "        .strip()\n",
    "    )\n",
    "    print(\"accepted\", m, t, fl, tl, \"start\")\n",
    "    bleu = BLEU.compute(\n",
    "        predictions=[gen_code], references=[[ref_code]], tokenizer=tokenizer.tokenize\n",
    "    )\n",
    "    bleus.append(bleu[\"bleu\"])\n",
    "    successes.append(1)\n",
    "    print(\"accepted\", m, t, fl, tl, \"done\")\n",
    "    if cnt % 10 == 0:\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"model\": models,\n",
    "                \"task\": tasks,\n",
    "                \"from_lang\": from_langs,\n",
    "                \"to_lang\": to_langs,\n",
    "                \"success\": successes,\n",
    "                \"valid\": valids,\n",
    "                \"bleu\": bleus,\n",
    "            }\n",
    "        ).to_csv(os.path.join(RESULTS_FOLDER, f\"metrics.csv\"), index=False)\n",
    "\n",
    "for filename in os.listdir(REJECTED_CODE_FOLDER):\n",
    "    if filename.startswith(\".\"):\n",
    "        continue\n",
    "    filename = filename.split(\".\")[0]\n",
    "    filename = filename.split(\"-\")\n",
    "    m = filename[0]\n",
    "    t = filename[1]\n",
    "    fl = filename[2]\n",
    "    tl = filename[3]\n",
    "    if check_row_exists(metrics, m, t, fl, tl):\n",
    "        continue\n",
    "    models.append(m)\n",
    "    tasks.append(t)\n",
    "    from_langs.append(fl)\n",
    "    to_langs.append(tl)\n",
    "    successes.append(0)\n",
    "    valids.append(0)\n",
    "    bleus.append(0)\n",
    "    print(\"rejected\", m, t, fl, tl, \"done\")\n",
    "\n",
    "metrics = pd.concat(\n",
    "    [\n",
    "        metrics,\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"model\": models,\n",
    "                \"task\": tasks,\n",
    "                \"from_lang\": from_langs,\n",
    "                \"to_lang\": to_langs,\n",
    "                \"success\": successes,\n",
    "                \"valid\": valids,\n",
    "                \"bleu\": bleus,\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>from_lang</th>\n",
       "      <th>to_lang</th>\n",
       "      <th>success</th>\n",
       "      <th>valid</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseekcoder7b</td>\n",
       "      <td>bit_ops</td>\n",
       "      <td>py</td>\n",
       "      <td>c</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>codellama7b</td>\n",
       "      <td>int_factors</td>\n",
       "      <td>rs</td>\n",
       "      <td>c</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>magicoder7b</td>\n",
       "      <td>int_factors</td>\n",
       "      <td>c</td>\n",
       "      <td>cpp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codellama7b</td>\n",
       "      <td>int_cmp</td>\n",
       "      <td>cpp</td>\n",
       "      <td>rs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.407748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codegeex4</td>\n",
       "      <td>bit_ops</td>\n",
       "      <td>py</td>\n",
       "      <td>js</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model         task from_lang to_lang  success  valid      bleu\n",
       "0  deepseekcoder7b      bit_ops        py       c      1.0    0.0  0.082299\n",
       "1      codellama7b  int_factors        rs       c      1.0    1.0  0.004715\n",
       "2      magicoder7b  int_factors         c     cpp      1.0    0.0  0.283290\n",
       "3      codellama7b      int_cmp       cpp      rs      1.0    1.0  0.407748\n",
       "4        codegeex4      bit_ops        py      js      1.0    1.0  0.012696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8754 entries, 0 to 8753\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   model      8754 non-null   object \n",
      " 1   task       8754 non-null   object \n",
      " 2   from_lang  8754 non-null   object \n",
      " 3   to_lang    8754 non-null   object \n",
      " 4   success    8754 non-null   float64\n",
      " 5   valid      8754 non-null   float64\n",
      " 6   bleu       8754 non-null   float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 478.9+ KB\n"
     ]
    }
   ],
   "source": [
    "_ = metrics.info()\n",
    "metrics.to_csv(os.path.join(RESULTS_FOLDER, f\"metrics.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              model  mean_valid  mean_bleu  mean_success\n",
      "12        yicoder9b    0.866947   0.220156      1.000000\n",
      "0         codegeex4    0.841737   0.153945      1.000000\n",
      "9       magicoder7b    0.781206   0.199551      0.998599\n",
      "3          codeqwen    0.754902   0.182459      1.000000\n",
      "4   deepseekcoder7b    0.721212   0.190979      0.982143\n",
      "6    dolphincoder7b    0.701556   0.168724      0.990196\n",
      "11        yicoder2b    0.663380   0.187130      0.990237\n",
      "1       codegemma7b    0.656863   0.202072      1.000000\n",
      "2       codellama7b    0.611833   0.189402      0.970588\n",
      "8     granitecode8b    0.538569   0.162156      0.998599\n",
      "5   deepseekcoderv2    0.607744   0.154792      0.815934\n",
      "7     granitecode3b    0.493653   0.166008      0.991608\n",
      "10       stablecode    0.230661   0.166756      0.995798\n"
     ]
    }
   ],
   "source": [
    "# per model metrics\n",
    "col = \"model\"\n",
    "m1_df = (\n",
    "    metrics[metrics[\"success\"] > 0]\n",
    "    .groupby(col)[[\"valid\", \"bleu\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"valid\": \"mean_valid\", \"bleu\": \"mean_bleu\"})\n",
    ")\n",
    "m2_df = (\n",
    "    metrics.groupby(col)\n",
    "    .success.mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"success\": \"mean_success\"})\n",
    ")\n",
    "m_df = m1_df.merge(m2_df, how=\"left\", on=col)\n",
    "m_df[\"rank\"] = m_df[\"mean_valid\"] * m_df[\"mean_success\"]\n",
    "m_df = m_df.sort_values([\"rank\", \"mean_bleu\"], ascending=False)\n",
    "m_df = m_df.drop(\"rank\", axis=1)\n",
    "print(m_df)\n",
    "m_df.to_csv(os.path.join(RESULTS_FOLDER, f\"{col}_metrics.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             task  mean_valid  mean_bleu  mean_success\n",
      "10     str_append    0.804781   0.200246      0.986248\n",
      "7         int_cmp    0.776536   0.262073      0.983516\n",
      "12     str_concat    0.755511   0.265137      0.990079\n",
      "13     str_interp    0.744467   0.217697      0.986111\n",
      "9       logic_ops    0.732932   0.324935      0.988095\n",
      "15    str_prepend    0.702213   0.101771      0.982213\n",
      "6       int_arith    0.717017   0.192141      0.956124\n",
      "5       file_size    0.635815   0.174800      0.986111\n",
      "4     file_rename    0.614000   0.231122      0.990099\n",
      "3     file_exists    0.606426   0.143890      0.988095\n",
      "2     file_create    0.598802   0.171282      0.992079\n",
      "14      str_match    0.583162   0.091603      0.964356\n",
      "1        dir_make    0.570565   0.155899      0.982178\n",
      "8     int_factors    0.567164   0.138560      0.981685\n",
      "0         bit_ops    0.546139   0.158474      0.972527\n",
      "11        str_cmp    0.540541   0.090310      0.954365\n",
      "16  str_substring    0.511202   0.131050      0.962745\n"
     ]
    }
   ],
   "source": [
    "# per task metrics\n",
    "col = \"task\"\n",
    "m1_df = (\n",
    "    metrics[metrics[\"success\"] > 0]\n",
    "    .groupby(col)[[\"valid\", \"bleu\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"valid\": \"mean_valid\", \"bleu\": \"mean_bleu\"})\n",
    ")\n",
    "m2_df = (\n",
    "    metrics.groupby(col)\n",
    "    .success.mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"success\": \"mean_success\"})\n",
    ")\n",
    "m_df = m1_df.merge(m2_df, how=\"left\", on=col)\n",
    "m_df[\"rank\"] = m_df[\"mean_valid\"] * m_df[\"mean_success\"]\n",
    "m_df = m_df.sort_values([\"rank\", \"mean_bleu\"], ascending=False)\n",
    "m_df = m_df.drop(\"rank\", axis=1)\n",
    "print(m_df)\n",
    "m_df.to_csv(os.path.join(RESULTS_FOLDER, f\"{col}_metrics.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  from_lang  mean_valid  mean_bleu  mean_success\n",
      "1       cpp    0.716029   0.190982      0.984776\n",
      "0         c    0.715581   0.172424      0.971955\n",
      "2        go    0.688578   0.181087      0.974380\n",
      "6        rs    0.645240   0.171472      0.979283\n",
      "3      java    0.627737   0.172558      0.984038\n",
      "5        py    0.575634   0.182346      0.977618\n",
      "4        js    0.568052   0.189018      0.981600\n"
     ]
    }
   ],
   "source": [
    "# per from_lang metrics\n",
    "col = \"from_lang\"\n",
    "m1_df = (\n",
    "    metrics[metrics[\"success\"] > 0]\n",
    "    .groupby(col)[[\"valid\", \"bleu\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"valid\": \"mean_valid\", \"bleu\": \"mean_bleu\"})\n",
    ")\n",
    "m2_df = (\n",
    "    metrics.groupby(col)\n",
    "    .success.mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"success\": \"mean_success\"})\n",
    ")\n",
    "m_df = m1_df.merge(m2_df, how=\"left\", on=col)\n",
    "m_df[\"rank\"] = m_df[\"mean_valid\"] * m_df[\"mean_success\"]\n",
    "m_df = m_df.sort_values([\"rank\", \"mean_bleu\"], ascending=False)\n",
    "m_df = m_df.drop(\"rank\", axis=1)\n",
    "print(m_df)\n",
    "m_df.to_csv(os.path.join(RESULTS_FOLDER, f\"{col}_metrics.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  to_lang  mean_valid  mean_bleu  mean_success\n",
      "4      js    0.895731   0.112481      0.975180\n",
      "5      py    0.860976   0.118030      0.983213\n",
      "3    java    0.698608   0.193464      0.977582\n",
      "6      rs    0.666939   0.167987      0.978383\n",
      "2      go    0.493917   0.213701      0.987190\n",
      "1     cpp    0.461979   0.236809      0.973726\n",
      "0       c    0.459150   0.217237      0.978417\n"
     ]
    }
   ],
   "source": [
    "# per to_lang metrics\n",
    "col = \"to_lang\"\n",
    "m1_df = (\n",
    "    metrics[metrics[\"success\"] > 0]\n",
    "    .groupby(col)[[\"valid\", \"bleu\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"valid\": \"mean_valid\", \"bleu\": \"mean_bleu\"})\n",
    ")\n",
    "m2_df = (\n",
    "    metrics.groupby(col)\n",
    "    .success.mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"success\": \"mean_success\"})\n",
    ")\n",
    "m_df = m1_df.merge(m2_df, how=\"left\", on=col)\n",
    "m_df[\"rank\"] = m_df[\"mean_valid\"] * m_df[\"mean_success\"]\n",
    "m_df = m_df.sort_values([\"rank\", \"mean_bleu\"], ascending=False)\n",
    "m_df = m_df.drop(\"rank\", axis=1)\n",
    "print(m_df)\n",
    "m_df.to_csv(os.path.join(RESULTS_FOLDER, f\"{col}_metrics.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model        task  mean_valid  mean_bleu  mean_success\n",
      "200    yicoder9b   logic_ops    1.000000   0.385792           1.0\n",
      "201    yicoder9b  str_append    1.000000   0.284128           1.0\n",
      "203    yicoder9b  str_concat    0.976190   0.313491           1.0\n",
      "198    yicoder9b     int_cmp    0.976190   0.285022           1.0\n",
      "7      codegeex4     int_cmp    0.976190   0.232491           1.0\n",
      "61      codeqwen  str_append    0.976190   0.219866           1.0\n",
      "149  magicoder7b   logic_ops    0.952381   0.369936           1.0\n",
      "9      codegeex4   logic_ops    0.952381   0.331193           1.0\n",
      "24   codegemma7b     int_cmp    0.952381   0.299689           1.0\n",
      "63      codeqwen  str_concat    0.952381   0.293744           1.0\n"
     ]
    }
   ],
   "source": [
    "# per model and task specific metrics\n",
    "col = [\"model\", \"task\"]\n",
    "m1_df = (\n",
    "    metrics[metrics[\"success\"] > 0]\n",
    "    .groupby(col)[[\"valid\", \"bleu\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"valid\": \"mean_valid\", \"bleu\": \"mean_bleu\"})\n",
    ")\n",
    "m2_df = (\n",
    "    metrics.groupby(col)\n",
    "    .success.mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"success\": \"mean_success\"})\n",
    ")\n",
    "m_df = m1_df.merge(m2_df, how=\"left\", on=col)\n",
    "m_df[\"rank\"] = m_df[\"mean_valid\"] * m_df[\"mean_success\"]\n",
    "m_df = m_df.sort_values([\"rank\", \"mean_bleu\"], ascending=False)\n",
    "m_df = m_df.drop(\"rank\", axis=1)\n",
    "print(m_df.head(10))\n",
    "m_df.to_csv(os.path.join(RESULTS_FOLDER, f\"{\"_\".join(col)}_metrics.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   from_lang to_lang  mean_valid  mean_bleu  mean_success\n",
      "9        cpp      js    0.911765   0.125750      0.980769\n",
      "21      java      js    0.902439   0.123055      0.985577\n",
      "15        go      js    0.905473   0.113780      0.966346\n",
      "10       cpp      py    0.878641   0.125636      0.990385\n",
      "34        py      js    0.882353   0.114234      0.980769\n",
      "40        rs      js    0.886700   0.096808      0.971292\n",
      "41        rs      py    0.873786   0.090171      0.985646\n",
      "3          c      js    0.885572   0.100980      0.966346\n",
      "28        js      py    0.858537   0.137138      0.985577\n",
      "22      java      py    0.858537   0.112728      0.976190\n"
     ]
    }
   ],
   "source": [
    "# per from_lang and to_lang specific metrics\n",
    "col = [\"from_lang\", \"to_lang\"]\n",
    "m1_df = (\n",
    "    metrics[metrics[\"success\"] > 0]\n",
    "    .groupby(col)[[\"valid\", \"bleu\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"valid\": \"mean_valid\", \"bleu\": \"mean_bleu\"})\n",
    ")\n",
    "m2_df = (\n",
    "    metrics.groupby(col)\n",
    "    .success.mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"success\": \"mean_success\"})\n",
    ")\n",
    "m_df = m1_df.merge(m2_df, how=\"left\", on=col)\n",
    "m_df[\"rank\"] = m_df[\"mean_valid\"] * m_df[\"mean_success\"]\n",
    "m_df = m_df.sort_values([\"rank\", \"mean_bleu\"], ascending=False)\n",
    "m_df = m_df.drop(\"rank\", axis=1)\n",
    "print(m_df.head(10))\n",
    "m_df.to_csv(os.path.join(RESULTS_FOLDER, f\"{\"_\".join(col)}_metrics.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
